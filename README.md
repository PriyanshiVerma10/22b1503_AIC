The goal of this machine learning project is to develop a system that interprets sign language gestures captured through a camera and converts them into text. 
 We plan to train ML algorithms on Sign Language MNIST and train a model using CNN which takes an image of hand gesture of American Sign Language and shows the output of the particular sign language in text format converts it into text.
 The project encompasses the basics of machine learning and computer vision.
